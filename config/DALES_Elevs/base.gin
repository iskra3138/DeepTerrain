#pred_type = 'sigmoid'
pred_type = 'tanh'
size = 512
# Data
DALESDataset.pred_type = %pred_type
DALESDataset.dataroot = '/nas2/YJ/DATA/ALS2DTM/'
#### input_list is combination of 'voxel-top', 'voxel-bottom', 'pixel-mean', 'density', 'stdev' and 'echoes'
DALESDataset.input_list = [
    "voxel-top" ,  'voxel-bottom', 'pixel-mean' #, 'density', 'stdev', 'echoes'
]
DALESDataset.size = %size

# Model
Pix2PixModel.pred_type = %pred_type
#Pix2PixModel.input_nc = 1 # number of input channels
Pix2PixModel.output_nc = 1 # number of output channels
Pix2PixModel.ngf = 64 # number of gen filters in the last conv layer
Pix2PixModel.ndf = 64 # number of discrim filters in the first conv layer
Pix2PixModel.netG = 'unet_256' # specify generator architecture [resnet_9blocks | resnet_6blocks | unet_256 | unet_128 ]
Pix2PixModel.netD = 'basic' # specify discriminator architecture [basic | n_layers | pixel]. The basic model is a 70x70 PatchGAN. n_layers allows you to specify the layers in the discriminator 
Pix2PixModel.norm = 'batch' # instance normalization or batch normalization [instance | batch | none]
Pix2PixModel.no_dropout = False # 
Pix2PixModel.init_type = 'normal' # 'network initialization [normal | xavier | kaiming | orthogonal]'
Pix2PixModel.init_gain = 0.02 # scaling factor for normal, xavier and orthogonal
Pix2PixModel.n_layers_D = 3 # only used if netD==n_layers 
Pix2PixModel.gan_mode = 'vanilla' # the type of GAN objective. [vanilla| lsgan | wgangp]. vanilla GAN loss is the cross-entropy objective used in the original GAN paper.
Pix2PixModel.verbose = False # if specified, print more debugging information
Pix2PixModel.aux_loss = 'gan' # gan, na, tv1, tv2
Pix2PixModel.size = %size

# Network
UnetSkipConnectionBlock.pred_type = %pred_type
